<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="CVPR 2019 Workshop on Adversarial Machine Learning in Real-World Computer Vision Systems">

  <title>Adversarial Machine Learning in Real-World Computer Vision Systems</title>

  <!-- Bootstrap core CSS -->
  <link href="bootstrap.min.css" rel="stylesheet">
</head>

<body>

<!-- Begin page content -->
<main role="main" class="container">
  <h1 class="mt-5">Adversarial Machine Learning in Real-World Computer Vision Systems
</h1>
  <p class="mb-0"><b>Date:</b> June, 16,2019</p>
  <p class="mb-0"><b>Location:</b> Long Beach, CA, USA (co-located with <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a>)</p>
  <!-- <p class="mb-0"><b>Contact:</b> xxx (this will email all organizers)</p> -->
  <p>
    <i>Abstract</i>—As computer vision models are being increasingly deployed in the real world, including applications that require safety considerations such as self-driving cars, it is imperative that these models are robust and secure even when subject to adversarial inputs. 
  </p>
  <p>
    This workshop will focus on recent research and future directions for security problems in real-world machine learning and computer vision systems. We aim to bring together experts from the computer vision, security, and robust learning communities in an attempt to highlight recent work in this area as well as to clarify the foundations of secure machine learning. We seek to come to a consensus on a rigorously framework to formulate adversarial machine learning problems in computer vision, characterize the properties that ensure the security of perceptual models, and evaluate the consequences under various adversarial models. Finally, we hope to chart out important directions for future work and cross-community collaborations, including computer vision, machine learning, security, and multimedia communities.
  </p>
  <!-- <h2>Sponsor</h2> -->
  <!-- <p></p> -->

  <h2>Schedule</h2>
  <p>The following is a tentative schedule and is subject to change prior to the workshop.</p>

  <table class="table table-sm">
    <tbody>
    <tr>
      <th scope="row">8:00am</th>
      <td>Opening Remarks</td>
      <td></td>
    </tr>

    <tr><th scope="row" colspan="3">Session 1:Interpretable Machine Learning Models</th></tr>
    <tr>
      <th scope="row">9:00am</th>
      <td>Invited Talk #1: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">9:30am</th>
      <td>Contributed Talk #1: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">10:00am</th>
      <td>Poster Spotlights #1: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">10:00am</th>
      <td>Coffee Break </td>
    </tr>
    <tr><th scope="row" colspan="3">Session 2:Adversarial Examples in Physical World </th></tr>
    <tr>
      <th scope="row">10:30am</th>
      <td>Invited Talk #2: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">11:00am</th>
      <td>Contributed Talk #2: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">11:15am</th>
      <td>Invited Talk #3: </td>
      <td></td>
    <tr>
      <th scope="row">11:45am</th>
      <td>Poster Spotlights #2: </td>
      <td></td>
    </tr>
    </tr>
    <tr>
      <th scope="row">12:00pm</th>
      <td>Lunch </td>
    </tr>
    <tr><th scope="row" colspan="3">Session 3:Improve Model Robustness Against Adversarial Examples</th></tr>
    
    <tr>
      <th scope="row">1:15pm</th>
      <td>Invited Talk #4: </td>
      <td><a target="_blank"></a></td>
    </tr>
    <tr>
      <th scope="row">1:45pm</th>
      <td>Contributed Talk #3:</td>
      <td></td>
    </tr>


    <!-- <tr><th scope="row" colspan="3">2:00pm</th></tr> -->
    <tr>
      <th scope="row">2:00pm</th>
      <td>Poster Session followed by break</td>
      <td></td>
    </tr>

    <tr><th scope="row" colspan="3">Session 4: Adversarial Machine Learning in Autonomous Driving
</th></tr>
    <tr>
      <th scope="row">2:45pm</th>
      <td>Invited Talk #5: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">3:15pm</th>
      <td>Contributed Talk #4: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">3:30pm</th>
      <td>Invited Talk #6: </td>
      <td></td>
    </tr>
    <tr>
      <th scope="row">4:00pm</th>
      <td>Contributed Talk #5: </td>
      <td></td>
    </tr>
    </tbody>
  </table>
  
<h2>Important Dates</h2>
<ul>
  <li style="color:red">Workshop paper submission deadline: 5/20/2019</li>
  <li>Notification to authors: 6/01/2019</li>
  <li>Camera ready deadline: 6/12/2019</li>
</ul>

	


	
	


<h2>Call For Papers</h2>
  <p class="mb-0" style="color:red;"><b>Submission deadline:</b> May 20, 2019 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Notification sent to authors:</b> June 7, 2019 Anywhere on Earth (AoE)</p>
  <p class="mb-0"><b>Submission server:</b> <a href="https://easychair.org/cfp/AdvMLCV2019" target="_blank">https://easychair.org/cfp/AdvMLCV2019</a></p>
	
  <p>The workshop will include contributed papers. Based on the PC’s recommendation, each paper accepted to the workshop will be allocated either a contributed talk or poster presentation .</p>
	<p>Submissions need to be anonymized. The workshop allows submissions of papers that are under review or have been recently published in a conference or a journal. The workshop will not have any official proceedings.</p>
  <p>We invite submissions on <b>any aspect of machine learning that relates to computer security (and vice versa)</b>. This includes, but is not limited to:</p>

  <ul>
	  <li> Test-time (exploratory) attacks: e.g. adversarial examples for neural nets</li>
<li> Training-time (causative) attacks: e.g. data poisoning
</li>
<li>Physical attacks/defenses</li>
<li>Differential privacy</li>
<li>Privacy preserving generative models</li>
<li>Game theoretic analysis on machine learning models</li>
<li> Manipulation of crowd-sourcing systems</li>
<li> Sybil detection</li>
<li>Exploitable bugs in ML systems</li>
<li>Formal verification of ML systems</li>
<li>Model stealing</li>
<li>Misuse of AI and deep learning</li>
<li> Interpretable machine learning</li>

  </ul>

  <h2>Organizing Committee</h2>
  <div class="row justify-content-around">
    <!-- <div class="col-lg-1"></div> -->
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/boli.jpg" width="100px" height="100px">
      <p style="width:100px" >Bo Li<br /></p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/lierranli.png" width="100px" height="100px">
      <p style="width:100px" >Li Erran Li<br /> </p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/david.jpeg" width="100px" height="100px">
      <p style="width:100px" >David forsyth</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/dawn.png" width="100px" height="100px">
      <p style="width:100px" >Dawn Song</p>
    </div>
    <div class="col-md-1">
      <img class="rounded-circle" src="imgs/ramin.jpeg" width="100px" height="100px">
      <p style="width:100px" >Ramin zabih</p>
    </div>
    <!-- </div> -->
      <div class="col-md-1">
      <img class="rounded-circle" src="imgs/chaowei2.png" width="100px" height="100px">
      <p style="width:100px" >Chaowei Xiao</p>
    </div>
  </div>
    <!-- <div class="col-lg-1"></div> -->
  </div>

<h2>Program Committee</h2>
<li>Bhavya Khailkhura (Lawrence Livermore National Lab)</li>
<li>Catherine Olsson (Google Brain)</li>
<li>Chaowei Xiao (University of Michigan)</li>
<li>David Evans (University of Virginia)</li>
<li>Dimitris Tsipras (Massachusetts Institute of Technology)</li>
<li>Earlence Fernandes (University of Washington)</li>
<li>Eric Wong (Carnegie Mellon University)</li>
<li>Fartash Faghri (University of Toronto)</li>
<li>Florian Tramer (Stanford University)</li>
<li>Hadi Abdullah (University of Florida)</li>
<li>Hao Su (UCSD)</li>
<li>Jonathan Uesato (DeepMind)</li>
<li>Karl Ni (In-Q-Tel)</li>
<li>Kassem Fawaz (University of Wisconsin-Madison)</li>
<li>Kathrin Grosse (CISPA)</li>
<li>Krishna Gummadi (MPI-SWS)</li>
<li>Matthew Wicker (University of Georgia)</li>
<li>Nathan Mundhenk (Lawrence Livermore National Lab)</li>
<li>Nicholas Carlini (Google Brain)</li>
<li>Nicolas Papernot (Google Brain and University of Toronto)</li>
<li>Octavian Suciu (University of Maryland)</li>
<li>Pin-Yu Chen (IBM)</li>
<li>Pushmeet Kohli (DeepMind)</li>
<li>Qian Chen (Tencent)</li>
<li> Qi Alfred Chen (UC Irvine) </li>
<li>Shreya Shankar (Stanford University)</li>
<li>Suman Jana (Columbia University)</li>
<li>Varun Chandrasekaran (University of Wisconsin-Madison)</li>
<li>Xiaowei Huang (Liverpool University)</li>
<li>Yanjun Qi (University of Virginia)</li>
<li>Yigitcan Kaya (University of Maryland)</li>
<li>Yizheng Chen (Georgia Tech)</li> 

</body></html>
